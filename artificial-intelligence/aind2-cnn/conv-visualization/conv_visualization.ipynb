{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we visualize four activation maps in a CNN layer.\n",
    "\n",
    "\n",
    "### 1. Import the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function cv::ipp_cvtColor\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-695094a3ea6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mbgr_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# convert to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mgray_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbgr_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# resize to smaller\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0msmall_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:7456: error: (-215) scn == 3 || scn == 4 in function cv::ipp_cvtColor\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import cv2\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO: Feel free to try out your own images here by changing img_path\n",
    "# to a file path to another image on your computer!\n",
    "img_path = 'images/udacity_sdc.png'\n",
    "\n",
    "# load color image \n",
    "bgr_img = cv2.imread(img_path)\n",
    "# convert to grayscale\n",
    "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "# resize to smaller\n",
    "small_img = scipy.misc.imresize(gray_img, 0.3)\n",
    "\n",
    "# rescale entries to lie in [0,1]\n",
    "small_img = small_img.astype(\"float32\")/255\n",
    "\n",
    "# plot image\n",
    "plt.imshow(small_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Specify the Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAACbCAYAAABhy5/wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQvsPuF27/A/zDmcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b91024cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Feel free to modify the numbers here, to try out another filter!\n",
    "# Please don't change the size of the array ~ :D\n",
    "filter_vals = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
    "\n",
    "### do not modify the code below this line ###\n",
    "\n",
    "# define four filters\n",
    "filter_1 = filter_vals\n",
    "filter_2 = -filter_1\n",
    "filter_3 = filter_1.T\n",
    "filter_4 = -filter_3\n",
    "filters = [filter_1, filter_2, filter_3, filter_4]\n",
    "\n",
    "# visualize all filters\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "    width, height = filters[i].shape\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(filters[i][x][y]), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if filters[i][x][y]<0 else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Visualize the Activation Maps for Each Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'small_img' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ee2fabaddd36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# plot image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmall_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# define a neural network with a single convolutional layer with one filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'small_img' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# plot image\n",
    "plt.imshow(small_img, cmap='gray')\n",
    "\n",
    "# define a neural network with a single convolutional layer with one filter\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(1, (4, 4), activation='relu', input_shape=(small_img.shape[0], small_img.shape[1], 1)))\n",
    "\n",
    "# apply convolutional filter and return output\n",
    "def apply_filter(img, index, filter_list, ax):\n",
    "    # set the weights of the filter in the convolutional layer to filter_list[i]\n",
    "    model.layers[0].set_weights([np.reshape(filter_list[i], (4,4,1,1)), np.array([0])])\n",
    "    # plot the corresponding activation map\n",
    "    ax.imshow(np.squeeze(model.predict(np.reshape(img, (1, img.shape[0], img.shape[1], 1)))), cmap='gray')\n",
    "\n",
    "# visualize all filters\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(filters[i], cmap='gray')\n",
    "    ax.set_title('Filter %s' % str(i+1))\n",
    "\n",
    "# visualize all activation maps\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "for i in range(4):\n",
    "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
    "    apply_filter(small_img, i, filters, ax)\n",
    "    ax.set_title('Activation Map for Filter %s' % str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}